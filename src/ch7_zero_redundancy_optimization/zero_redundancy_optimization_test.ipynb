{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a5fce-dfea-4600-a60e-290cbfd9efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size, hidden_size =4, 8\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.z1 = None\n",
    "        self.w1 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_size, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.w1(x)\n",
    "        print(z1)\n",
    "        self.z1 = z1.clone().detach()\n",
    "        z2 = self.w2(z1)\n",
    "        return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47aa79f-c606-452e-8773-8035f1086b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params / 1e9:.1f}G\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2c6131-3c95-439b-ba28-40dd0d5f8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "fp32_model= Net().to(\"cuda\")\n",
    "lr = 1e-0\n",
    "optimizer = SGD(fp32_model.parameters(), lr=lr)\n",
    "# print(lr)  #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a695d1-dba8-43eb-80bf-712b3f357c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1316,  0.0437,  0.3298, -0.1907,  0.2609,  0.2583,  0.1089,  0.3062],\n",
       "        [-0.0842,  0.2763, -0.3430, -0.1335, -0.0554,  0.2907,  0.1734,  0.0947],\n",
       "        [ 0.0371, -0.0304,  0.1951, -0.3194, -0.3333, -0.0392, -0.0669, -0.1214],\n",
       "        [-0.3199,  0.2473, -0.0599,  0.0925, -0.2743,  0.1447,  0.1477, -0.0938],\n",
       "        [ 0.0281,  0.3230,  0.2939,  0.2553, -0.0854,  0.2849,  0.2011, -0.2587],\n",
       "        [-0.1827, -0.0532, -0.0823,  0.2022,  0.0876,  0.1245,  0.3236,  0.2002],\n",
       "        [ 0.1658,  0.2610,  0.0143, -0.1296,  0.1480,  0.2264,  0.0457,  0.3042],\n",
       "        [-0.0736,  0.0768, -0.2696, -0.2455, -0.2354,  0.1226, -0.2516,  0.0230]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_model.w1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9602758d-c346-480e-aef1-f2ba311e870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.8533, -1.6335, -3.1606, -2.5019, -2.7972,  1.6775, -2.6429, -2.4407]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_model.w2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22649bc8-db08-49c6-83d4-44d85a979aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6157,  1.1022, -0.7334,  0.6155,  0.1529,  0.6115,  0.2666,  0.0737],\n",
      "        [-0.8183, -0.5411, -0.4788, -0.5367, -0.6478,  0.1682, -0.5512, -0.3209],\n",
      "        [ 0.6724, -0.3931,  0.2992,  0.0016,  0.3233,  0.2226,  0.0595, -0.6364],\n",
      "        [-0.6500, -0.2179, -0.4946, -0.4452,  0.0377,  0.3786, -0.2514, -0.6484]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logits type = torch.float32'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# example input sizes\n",
    "#batch_size, hidden_size =4, 8\n",
    "\n",
    "# create dummy data (bsz=4, hid=256)\n",
    "x = torch.randn(batch_size,hidden_size, dtype=torch.float, device=\"cuda\") \n",
    "\n",
    "# do forward\n",
    "z2 = fp32_model(x)\n",
    "\n",
    "# check dtypr of output logits\n",
    "f\"logits type = {z2.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d02965d-c80d-4889-8215-97cdacfbca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss type = torch.float32'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# craete dummy data (bsz=4)\n",
    "#y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.half, device=\"cuda\") #batch_size =4\n",
    "y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.float32, device=\"cuda\") #batch_size =4\n",
    "#y = torch.tensor([[1.9]], dtype=torch.float32, device=\"cuda\")\n",
    "#y = torch.tensor([[1.9], [0.5]], dtype=torch.float32, device=\"cuda\")\n",
    "# compute mean square error loss\n",
    "L = torch.nn.functional.mse_loss(z2, y)\n",
    "\n",
    "# check dtype of loss\n",
    "f\"loss type = {L.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae67a22d-da80-4ae1-9e21-a42fb1205b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.0975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0857],\n",
      "        [-0.7735],\n",
      "        [ 0.3088],\n",
      "        [-0.3974]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[1.9000],\n",
      "        [9.5000],\n",
      "        [0.9000],\n",
      "        [1.2000]], device='cuda:0')\n",
      "tensor(28.0975, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(L)\n",
    "print(z2)\n",
    "print(y)\n",
    "loss = torch.sum((z2-y)**2/batch_size)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aef694d-05a1-4e10-9161-bf8604f21e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Parameter containing:\n",
      "tensor([[ 0.2819,  0.3416,  0.3337, -0.0009,  0.2527, -0.1617,  0.1073, -0.1597]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[-4.8533, -1.6335, -3.1606, -2.5019, -2.7972,  1.6775, -2.6429, -2.4407]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L.backward()\n",
    "w2_weight = fp32_model.w2.weight.clone().detach()\n",
    "w1_weight = fp32_model.w1.weight.clone().detach()\n",
    "print(f'before: {fp32_model.w2.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w2.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781fba10-4815-4e48-a771-bcd19292e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9929],\n",
      "        [-5.1368],\n",
      "        [-0.2956],\n",
      "        [-0.7987]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([4, 8])\n",
      "tensor([[-0.6157,  1.1022, -0.7334,  0.6155,  0.1529,  0.6115,  0.2666,  0.0737],\n",
      "        [-0.8183, -0.5411, -0.4788, -0.5367, -0.6478,  0.1682, -0.5512, -0.3209],\n",
      "        [ 0.6724, -0.3931,  0.2992,  0.0016,  0.3233,  0.2226,  0.0595, -0.6364],\n",
      "        [-0.6500, -0.2179, -0.4946, -0.4452,  0.0377,  0.3786, -0.2514, -0.6484]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 8])\n",
      "tensor([[ 5.1351,  1.9751,  3.4944,  2.5010,  3.0499, -1.8392,  2.7502,  2.2809]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[ 0.2819,  0.3416,  0.3337, -0.0009,  0.2527, -0.1617,  0.1073, -0.1597]],\n",
      "       device='cuda:0')\n",
      "tensor([[-4.8533, -1.6335, -3.1606, -2.5019, -2.7972,  1.6775, -2.6429, -2.4407]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "DL_Dz2= 2 * (z2 - y) / batch_size # DL/Dz2  (BWD-activation: layer2), in case of MSE\n",
    "print(DL_Dz2) # [4,1] [output_size=1, batch_size] DL/Dz2\n",
    "Dz2_Dw2 = fp32_model.z1.clone().detach() #Dz2/Dw2\n",
    "print(Dz2_Dw2.shape) #[4,8] [batch_size, hidden_size] \n",
    "print(Dz2_Dw2)\n",
    "#DL_Dw2 = DL_Dz2.T * Dz2_Dw2\n",
    "DL_Dw2 = torch.matmul(DL_Dz2.T, Dz2_Dw2) #[1,4] * [4,8] batch_size, hidden_size\n",
    "print(DL_Dw2.shape) # [1,8] [output_size=1, hidden_size]\n",
    "print(DL_Dw2)\n",
    "print(w2_weight) # [hidden_size=8 , output_size=1]\n",
    "print(w2_weight - lr * DL_Dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2dbab75-ab40-44ef-a2eb-3a73f57026ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1200, -1.7049, -1.4670,  1.9101,  0.4296, -1.2090,  0.7812,  0.4647],\n",
       "        [ 1.4326, -1.8428, -2.5207,  2.4125,  0.1490, -1.4875,  0.9882,  0.2869],\n",
       "        [ 1.5189, -2.1006, -1.9323,  2.1679, -0.1337, -1.7764,  0.7291,  0.0664],\n",
       "        [-0.3240,  0.2529, -0.0541,  0.0857, -0.2748,  0.1494,  0.1455, -0.0943],\n",
       "        [ 1.1499, -1.2443, -1.3167,  2.1383,  0.0658, -1.0303,  0.8037, -0.1166],\n",
       "        [-0.9005,  0.9496,  0.9482, -1.0026, -0.0091,  0.9660, -0.0619,  0.1092],\n",
       "        [ 0.6421, -0.4044, -0.6695,  0.6699,  0.2122, -0.3320,  0.3015,  0.3645],\n",
       "        [-0.7828,  1.0677,  0.7487, -1.4360, -0.3309,  0.9541, -0.6326, -0.0668]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_model.w1.weight # w1 = [hidden_size, hidden_size] [8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0166765e-a2a7-456b-89a9-5c3accbc5658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9929],\n",
      "        [-5.1368],\n",
      "        [-0.2956],\n",
      "        [-0.7987]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([1, 8])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([8, 8])\n",
      "tensor([[ 1.1200, -1.7049, -1.4670,  1.9101,  0.4296, -1.2090,  0.7812,  0.4647],\n",
      "        [ 1.4326, -1.8428, -2.5207,  2.4125,  0.1490, -1.4875,  0.9882,  0.2869],\n",
      "        [ 1.5189, -2.1006, -1.9323,  2.1679, -0.1337, -1.7764,  0.7291,  0.0664],\n",
      "        [-0.3240,  0.2529, -0.0541,  0.0857, -0.2748,  0.1494,  0.1455, -0.0943],\n",
      "        [ 1.1499, -1.2443, -1.3167,  2.1383,  0.0658, -1.0303,  0.8037, -0.1166],\n",
      "        [-0.9005,  0.9496,  0.9482, -1.0026, -0.0091,  0.9660, -0.0619,  0.1092],\n",
      "        [ 0.6421, -0.4044, -0.6695,  0.6699,  0.2122, -0.3320,  0.3015,  0.3645],\n",
      "        [-0.7828,  1.0677,  0.7487, -1.4360, -0.3309,  0.9541, -0.6326, -0.0668]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "DL_Dz2= 2 * (z2 - y) / batch_size # DL/Dz2  (BWD-activation: layer2), in case of MSE\n",
    "print(DL_Dz2) # [4,1] [batch_size=4, output_size=1]\n",
    "print(w2_weight.shape) # [1,8]\n",
    "temp = torch.matmul(DL_Dz2, w2_weight) #DL/Dz2 * w2\n",
    "print(temp.shape) # [4,8]\n",
    "print(x.shape) # [4,8]\n",
    "DL_Dw1 = torch.matmul(temp.T, x) # [8,4] * [4,8] = [8,8]\n",
    "print(DL_Dw1.shape) #[8,8]\n",
    "print(w1_weight - lr * DL_Dw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20942146-5f0b-4c2c-b02a-5c0e9255a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(512, 512, bias=False)\n",
    "        self.w2 = nn.Linear(512, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.w1(x)\n",
    "        z2 = self.w2(z1)\n",
    "        return z2\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "fp32_model= Net().to(\"cuda\")\n",
    "optimizer = SGD(fp32_model.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f77d7-ecc4-461b-b36f-81139c9eb1b5",
   "metadata": {},
   "source": [
    "### Float2Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79d4a4a-92ec-4cbc-9378-36f18a8d0c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp16_model = Net().half().to(\"cuda\")\n",
    "fp16_model.load_state_dict(fp32_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ffd276-1902-46c2-86de-83abd542298b",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3877d42-2c6d-44d6-9df1-1f6778f2758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logits type = torch.float16'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# example input sizes\n",
    "batch_size, hidden_size = 4, 512\n",
    "\n",
    "# create dummy data (bsz=4, hid=256)\n",
    "x = torch.randn(batch_size,hidden_size, dtype=torch.half, device=\"cuda\") \n",
    "\n",
    "# do forward\n",
    "z2 = fp16_model(x)\n",
    "\n",
    "# check dtypr of output logits\n",
    "f\"logits type = {z2.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdde465-eb37-4d50-87ec-b561e8c21f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss type = torch.float16'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# craete dummy data (bsz=4)\n",
    "y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.half, device=\"cuda\")\n",
    "\n",
    "# compute mean square error loss\n",
    "L = torch.nn.functional.mse_loss(z2, y)\n",
    "\n",
    "# check dtype of loss\n",
    "f\"loss type = {L.dtype}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8bbdd-8569-41d0-87cc-93f842e88377",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfa9df7-48b2-419c-85c5-73256959455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss scaling\n",
    "L *= 1024\n",
    "\n",
    "# do backward\n",
    "L.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3d467-45c6-4d1d-864b-f34cb185fe10",
   "metadata": {},
   "source": [
    "### Update Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e749deb2-6b96-4595-b3f1-c3d05e6d147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Parameter containing:\n",
      "tensor([[ 0.0014, -0.0054, -0.0113,  ...,  0.0319, -0.0107, -0.0092],\n",
      "        [-0.0171,  0.0104, -0.0103,  ..., -0.0259, -0.0431, -0.0075],\n",
      "        [-0.0423, -0.0418,  0.0213,  ..., -0.0251,  0.0348,  0.0121],\n",
      "        ...,\n",
      "        [ 0.0361, -0.0298, -0.0226,  ..., -0.0069, -0.0387,  0.0304],\n",
      "        [ 0.0351,  0.0207,  0.0058,  ..., -0.0041, -0.0299,  0.0108],\n",
      "        [ 0.0368, -0.0269,  0.0004,  ..., -0.0361, -0.0273, -0.0195]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[ 0.0014, -0.0054, -0.0113,  ...,  0.0319, -0.0107, -0.0092],\n",
      "        [-0.0171,  0.0104, -0.0103,  ..., -0.0259, -0.0431, -0.0075],\n",
      "        [-0.0423, -0.0418,  0.0213,  ..., -0.0251,  0.0348,  0.0121],\n",
      "        ...,\n",
      "        [ 0.0361, -0.0298, -0.0226,  ..., -0.0069, -0.0387,  0.0304],\n",
      "        [ 0.0351,  0.0207,  0.0058,  ..., -0.0041, -0.0299,  0.0108],\n",
      "        [ 0.0368, -0.0269,  0.0004,  ..., -0.0361, -0.0273, -0.0195]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65aa4065-1520-444a-b6c3-99c1b57b9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'before: {fp16_model.w1.weight}\\n')\n",
    "#optimizer.step()\n",
    "#print(f'after: {fp16_model.w1.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559310f0-09bc-4636-923d-9502f1f17f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy gradient to FP32 model\n",
    "fp32_model.w1.weight.grad = fp16_model.w1.weight.grad.float()\n",
    "fp32_model.w2.weight.grad = fp16_model.w2.weight.grad.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b6ac53-8d55-4732-b125-0b588078c1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Parameter containing:\n",
      "tensor([[ 0.0014, -0.0054, -0.0113,  ...,  0.0319, -0.0107, -0.0092],\n",
      "        [-0.0171,  0.0104, -0.0103,  ..., -0.0259, -0.0431, -0.0075],\n",
      "        [-0.0423, -0.0418,  0.0213,  ..., -0.0251,  0.0348,  0.0121],\n",
      "        ...,\n",
      "        [ 0.0361, -0.0298, -0.0226,  ..., -0.0069, -0.0387,  0.0304],\n",
      "        [ 0.0351,  0.0207,  0.0058,  ..., -0.0041, -0.0299,  0.0108],\n",
      "        [ 0.0368, -0.0269,  0.0004,  ..., -0.0361, -0.0273, -0.0195]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[-0.1877,  0.5187, -0.0540,  ...,  0.0834, -0.7445,  0.2320],\n",
      "        [ 0.4882, -1.3909,  0.1039,  ..., -0.1635,  1.9181, -0.6525],\n",
      "        [-0.2927,  0.6520, -0.0352,  ...,  0.0430, -0.9364,  0.3314],\n",
      "        ...,\n",
      "        [-1.0620,  3.0127, -0.2704,  ...,  0.2918, -4.3012,  1.4316],\n",
      "        [ 0.2854, -0.6731,  0.0623,  ..., -0.0722,  0.9413, -0.3086],\n",
      "        [ 0.8568, -2.3006,  0.1856,  ..., -0.2593,  3.1552, -1.0664]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac8890c-f6a8-4a06-958d-25eb613a593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 grad: None\n",
      "\n",
      "before: Parameter containing:\n",
      "tensor([[-0.0324,  0.0434, -0.0429,  ...,  0.0384, -0.0291, -0.0340],\n",
      "        [ 0.0010, -0.0153,  0.0097,  ...,  0.0374, -0.0176, -0.0270],\n",
      "        [-0.0366, -0.0296,  0.0203,  ..., -0.0179, -0.0196, -0.0239],\n",
      "        ...,\n",
      "        [-0.0436, -0.0131,  0.0017,  ..., -0.0360,  0.0416, -0.0143],\n",
      "        [-0.0170,  0.0044, -0.0296,  ..., -0.0230,  0.0356, -0.0095],\n",
      "        [ 0.0061,  0.0173,  0.0191,  ..., -0.0371,  0.0421,  0.0111]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[-0.0324,  0.0434, -0.0429,  ...,  0.0384, -0.0291, -0.0340],\n",
      "        [ 0.0010, -0.0153,  0.0097,  ...,  0.0374, -0.0176, -0.0270],\n",
      "        [-0.0366, -0.0296,  0.0203,  ..., -0.0179, -0.0196, -0.0239],\n",
      "        ...,\n",
      "        [-0.0436, -0.0131,  0.0017,  ..., -0.0360,  0.0416, -0.0143],\n",
      "        [-0.0170,  0.0044, -0.0296,  ..., -0.0230,  0.0356, -0.0095],\n",
      "        [ 0.0061,  0.0173,  0.0191,  ..., -0.0371,  0.0421,  0.0111]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "fp32 grad: None\n",
      "\n",
      "f16 grad: tensor([[ 0.2010,  0.1113, -0.0122,  ...,  0.0028,  0.0174,  0.0506],\n",
      "        [ 0.4502,  0.2491, -0.0273,  ...,  0.0062,  0.0390,  0.1133],\n",
      "        [ 0.1787,  0.0989, -0.0109,  ...,  0.0025,  0.0155,  0.0450],\n",
      "        ...,\n",
      "        [ 0.4531,  0.2510, -0.0275,  ...,  0.0063,  0.0393,  0.1141],\n",
      "        [ 0.3484,  0.1929, -0.0212,  ...,  0.0048,  0.0302,  0.0877],\n",
      "        [-0.2109, -0.1168,  0.0128,  ..., -0.0029, -0.0183, -0.0531]],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "before: Parameter containing:\n",
      "tensor([[-0.0324,  0.0434, -0.0429,  ...,  0.0384, -0.0291, -0.0340],\n",
      "        [ 0.0010, -0.0153,  0.0097,  ...,  0.0374, -0.0176, -0.0270],\n",
      "        [-0.0366, -0.0296,  0.0203,  ..., -0.0179, -0.0196, -0.0239],\n",
      "        ...,\n",
      "        [-0.0436, -0.0131,  0.0017,  ..., -0.0360,  0.0416, -0.0143],\n",
      "        [-0.0170,  0.0044, -0.0296,  ..., -0.0230,  0.0356, -0.0095],\n",
      "        [ 0.0061,  0.0173,  0.0191,  ..., -0.0371,  0.0421,  0.0111]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[-0.0344,  0.0423, -0.0428,  ...,  0.0384, -0.0293, -0.0345],\n",
      "        [-0.0035, -0.0178,  0.0100,  ...,  0.0373, -0.0180, -0.0281],\n",
      "        [-0.0384, -0.0306,  0.0204,  ..., -0.0179, -0.0198, -0.0243],\n",
      "        ...,\n",
      "        [-0.0481, -0.0156,  0.0020,  ..., -0.0360,  0.0412, -0.0155],\n",
      "        [-0.0205,  0.0025, -0.0294,  ..., -0.0231,  0.0353, -0.0104],\n",
      "        [ 0.0082,  0.0185,  0.0189,  ..., -0.0371,  0.0423,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint(f'before: {fp16_model.w1.weight}\\n')\\nprint(fp16_model.w1.weight.grad)\\noptimizer.step()\\nprint(fp16_model.w1.weight.grad)\\nprint(f'after: {fp16_model.w1.weight}\\n')\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(512, 512, bias=False)\n",
    "        self.w2 = nn.Linear(512, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.w1(x)\n",
    "        z2 = self.w2(z1)\n",
    "        return z2\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "fp32_model= Net().to(\"cuda\")\n",
    "optimizer = SGD(fp32_model.parameters(), lr=1e-2)\n",
    "#optimizer = SGD(fp32_model.parameters(), lr=1e-0)\n",
    "\n",
    "### Float2Half\n",
    "fp16_model = Net().half().to(\"cuda\")\n",
    "fp16_model.load_state_dict(fp32_model.state_dict())\n",
    "\n",
    "### Forward\n",
    "import torch\n",
    "\n",
    "# example input sizes\n",
    "batch_size, hidden_size = 4, 512\n",
    "\n",
    "# create dummy data (bsz=4, hid=256)\n",
    "x = torch.randn(batch_size,hidden_size, dtype=torch.half, device=\"cuda\") \n",
    "\n",
    "# do forward\n",
    "z2 = fp16_model(x)\n",
    "\n",
    "# check dtypr of output logits\n",
    "f\"logits type = {z2.dtype}\"\n",
    "\n",
    "\n",
    "# craete dummy data (bsz=4)\n",
    "y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.half, device=\"cuda\")\n",
    "\n",
    "# compute mean square error loss\n",
    "L = torch.nn.functional.mse_loss(z2, y)\n",
    "\n",
    "# check dtype of loss\n",
    "f\"loss type = {L.dtype}\"\n",
    "\n",
    "### Backward\n",
    "# loss scaling\n",
    "#L *= 1024\n",
    "\n",
    "# do backward\n",
    "L.backward()\n",
    "\n",
    "print(f'fp32 grad: {fp32_model.w1.weight.grad}\\n')\n",
    "### Update Weight\n",
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')\n",
    "print(f'fp32 grad: {fp32_model.w1.weight.grad}\\n')\n",
    "\n",
    "\n",
    "print(f'f16 grad: {fp16_model.w1.weight.grad}\\n')\n",
    "\n",
    "# copy gradient to FP32 model\n",
    "fp32_model.w1.weight.grad = fp16_model.w1.weight.grad.float()\n",
    "fp32_model.w2.weight.grad = fp16_model.w2.weight.grad.float()\n",
    "\n",
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')\n",
    "\n",
    "\"\"\"\n",
    "print(f'before: {fp16_model.w1.weight}\\n')\n",
    "print(fp16_model.w1.weight.grad)\n",
    "optimizer.step()\n",
    "print(fp16_model.w1.weight.grad)\n",
    "print(f'after: {fp16_model.w1.weight}\\n')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171476-fd05-413e-914a-fa20b2d81e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mega",
   "language": "python",
   "name": "mega"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
